{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6fb6e22-5860-453f-9373-bc341d153ed5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tiktoken\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "from retry import retry\n",
    "import copy\n",
    "import random\n",
    "import json\n",
    "import jsonlines\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74742791-5b13-44aa-ac86-2dd0eb6276a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_file = './Data/FineTuning/train_log4j.tsv'\n",
    "train_inputs = pd.read_csv(train_file, sep='\\t', header=None)[0].tolist()\n",
    "train_targets = pd.read_csv(train_file, sep='\\t', header=None)[1].tolist()\n",
    "\n",
    "test_file = './Data/FineTuning/test_log4j.tsv'\n",
    "test_inputs = pd.read_csv(test_file, sep='\\t', header=None)[0].tolist()\n",
    "test_targets = pd.read_csv(test_file, sep='\\t', header=None)[1].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669b237f-a008-4783-a68c-f8517b586e3f",
   "metadata": {},
   "source": [
    "# Cost Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b63f30fa-1e46-41e9-a519-1b8043deab86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6811/6811 [00:01<00:00, 6419.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Simple Prompt:\n",
      "cost of GPT-4: 139.48959\n",
      "cost of GPT-4-Turbo: 61.42779\n",
      "cost of GPT-4o: 30.713895\n",
      "cost of GPT-3.5-Turbo: 3.0713895000000004\n",
      "\n",
      "\n",
      "Using Role Prompt:\n",
      "cost of GPT-4: 143.37186\n",
      "cost of GPT-4-Turbo: 62.72188\n",
      "cost of GPT-4o: 31.36094\n",
      "cost of GPT-3.5-Turbo: 3.1360940000000004\n",
      "\n",
      "\n",
      "Using Instruction Prompt:\n",
      "cost of GPT-4: 236.75066999999999\n",
      "cost of GPT-4-Turbo: 93.84815\n",
      "cost of GPT-4o: 46.924075\n",
      "cost of GPT-3.5-Turbo: 4.6924075\n",
      "cost of GPT-3.5-Turbo (legacy): 13.3306595\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "simple_prompt = \"You will be provided with a Java method. Your task is to inject at least one logging statement at a \" \\\n",
    "                    \"rational logging point.\"\n",
    "role_prompt = \"You are a logging statement generator for Java. \" \\\n",
    "                  \"You will be provided with a Java method as input. \" \\\n",
    "                  \"Your task is to inject at least one logging statement at a rational position. \" \\\n",
    "                  \"The output must be a completed Java method.\"\n",
    "example_input = train_inputs[39358]\n",
    "example_output = train_targets[39358]\n",
    "instruction_prompt = \"Please Analyze the following provided code in Java. \" \\\n",
    "                        \"Generate at least one logging statements and inject it to the provided Code. \" \\\n",
    "                        \"Logging statement consist of logging level, logging message, and logging variable. \" \\\n",
    "                        \"Here are an example: \" \\\n",
    "                        \"The example input is \" + example_input + \", \" \\\n",
    "                        \"Ths example output is \" + example_output + \".\" \\\n",
    "                        \"The output must be a completed Java method. \" \n",
    "\n",
    "simple_prompt_tokens = encoding.encode(simple_prompt)\n",
    "role_prompt_tokens = encoding.encode(role_prompt)\n",
    "instruction_prompt_tokens = encoding.encode(instruction_prompt)\n",
    "\n",
    "total_tokens_input = list()\n",
    "total_tokens_output = list()\n",
    "for idx in tqdm(range(len(inputs))):\n",
    "    input_tokens = encoding.encode(inputs[idx])\n",
    "    output_tokens = encoding.encode(inputs[idx])\n",
    "\n",
    "    total_tokens_input.append(len(input_tokens))\n",
    "    total_tokens_output.append(len(output_tokens))\n",
    "    \n",
    "num_input_tokens_sp = len(inputs)*len(simple_prompt_tokens) + sum(total_tokens_input)\n",
    "num_input_tokens_role = len(inputs)*len(role_prompt_tokens) + sum(total_tokens_input)\n",
    "num_input_tokens_inst = len(inputs)*len(instruction_prompt_tokens) + sum(total_tokens_input)\n",
    "\n",
    "print('Using Simple Prompt:')\n",
    "print('cost of GPT-4:', (((0.03/1000) * num_input_tokens_sp) + ((0.06/1000) * sum(total_tokens_output))))\n",
    "print('cost of GPT-4-Turbo:', (((0.01/1000) * num_input_tokens_sp) + ((0.03/1000) * sum(total_tokens_output))))\n",
    "print('cost of GPT-4o:', (((0.005/1000) * num_input_tokens_sp) + ((0.015/1000) * sum(total_tokens_output))))\n",
    "print('cost of GPT-3.5-Turbo:', (((0.0005/1000) * num_input_tokens_sp) + ((0.0015/1000) * sum(total_tokens_output))))\n",
    "print('\\n')\n",
    "\n",
    "print('Using Role Prompt:')\n",
    "print('cost of GPT-4:', (((0.03/1000) * num_input_tokens_role) + ((0.06/1000) * sum(total_tokens_output))))\n",
    "print('cost of GPT-4-Turbo:', (((0.01/1000) * num_input_tokens_role) + ((0.03/1000) * sum(total_tokens_output))))\n",
    "print('cost of GPT-4o:', (((0.005/1000) * num_input_tokens_role) + ((0.015/1000) * sum(total_tokens_output))))\n",
    "print('cost of GPT-3.5-Turbo:', (((0.0005/1000) * num_input_tokens_role) + ((0.0015/1000) * sum(total_tokens_output))))\n",
    "print('\\n')\n",
    "\n",
    "print('Using Instruction Prompt:')\n",
    "print('cost of GPT-4:', (((0.03/1000) * num_input_tokens_inst) + ((0.06/1000) * sum(total_tokens_output))))\n",
    "print('cost of GPT-4-Turbo:', (((0.01/1000) * num_input_tokens_inst) + ((0.03/1000) * sum(total_tokens_output))))\n",
    "print('cost of GPT-4o:', (((0.005/1000) * num_input_tokens_inst) + ((0.015/1000) * sum(total_tokens_output))))\n",
    "print('cost of GPT-3.5-Turbo:', (((0.0005/1000) * num_input_tokens_inst) + ((0.0015/1000) * sum(total_tokens_output))))\n",
    "print('cost of GPT-3.5-Turbo (legacy):', (((0.0015/1000) * num_input_tokens_inst) + ((0.0040/1000) * sum(total_tokens_output))))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c091563-6f5c-40a9-a1fa-97c7406661f2",
   "metadata": {},
   "source": [
    "# Batch Dataset Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81047d23-f719-4712-9176-281d95fe4e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_prompt = \"You will be provided with a Java method. Your task is to inject at least one logging statement at a \" \\\n",
    "                    \"rational logging point.\"\n",
    "role_prompt = \"You are a logging statement generator for Java. \" \\\n",
    "                  \"You will be provided with a Java method as input. \" \\\n",
    "                  \"Your task is to inject at least one logging statement at a rational position. \" \\\n",
    "                  \"The output must be a completed Java method.\"\n",
    "example_input = train_inputs[39358]\n",
    "example_output = train_targets[39358]\n",
    "instruction_prompt = \"Please Analyze the following provided code in Java. \" \\\n",
    "                        \"Generate at least one logging statement and inject it to the provided code. \" \\\n",
    "                        \"Logging statement is embedded in source code to understand system behavior, monitoring choke-points and debugging. \" \\\n",
    "                        \"A logging statement consist of logging level, logging message, and/or logging variable. \" \\\n",
    "                        \"The output must be a completed Java method. \\n\" \\\n",
    "                        \"Here are an example:\\n\" \\\n",
    "                        \"```The example input is\\n\" + example_input + \"\\n```\\n\" \\\n",
    "                        \"```The example output is\\n\" + example_output + \"\\n```\\n\" \\\n",
    "                        \"In this example, the generated logging statement for input is \" + '''\\'LOG . info ( \"Received node: \" + node . getIdentity ( ) + \" status: \" + node . getStatus ( ) + \" type: \" + node . getType ( ) ) ;\\'. ''' + \"The generated logging statement is injected in the FOR loop \\'for ( CssNode node : nodes ) { }\\'.\"\n",
    "\n",
    "prompt_type = {\"simple\": simple_prompt, \n",
    "                \"role\": role_prompt,\n",
    "                \"instruction\": instruction_prompt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1bc5d6c1-9c0e-4a19-b605-991de678d81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens = 512\n",
    "model = \"gpt-3.5-turbo-0613\"\n",
    "\n",
    "batch = []\n",
    "for i in range(len(test_inputs)):\n",
    "    custom_id = \"request-\" + str(i+1)\n",
    "    prompt = prompt_type[\"instruction\"]\n",
    "    request = {\"custom_id\": custom_id, \n",
    "               \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \n",
    "               \"body\": {\"model\": model,\n",
    "                        \"messages\":[{\"role\": \"system\", \"content\": prompt},{\"role\": \"user\", \"content\": test_inputs[i]}], \n",
    "                        \"max_tokens\": max_tokens}}\n",
    "    batch.append(request)\n",
    "\n",
    "def save_list_as_jsonl(file_path, data):\n",
    "    with open(file_path, 'w') as f:\n",
    "        for item in data:\n",
    "            json.dump(item, f)\n",
    "            f.write('\\n')\n",
    "\n",
    "# save_list_as_jsonl('./gpt-3.5-turbo_simple_prompt_inputs.jsonl', batch)\n",
    "# save_list_as_jsonl('./gpt-3.5-turbo_role_prompt_inputs.jsonl', batch)\n",
    "save_list_as_jsonl('./gpt-3.5-turbo_instruction_prompt_inputs.jsonl', batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c4f8c4-cef9-408d-bcad-860c0b43f629",
   "metadata": {},
   "source": [
    "# GPT-3.5-Turbo Batch Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d211c7d-c70d-428d-a5d7-bc1475522b15",
   "metadata": {},
   "source": [
    "### simple prompt version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd5f4c3e-b134-40ca-9d02-7fedcd5d8bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "api_key = ''\n",
    "client = OpenAI(api_key = api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9f9e4ff7-17a8-4a88-b644-53dc0bb408a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_input_file = client.files.create(\n",
    "  file=open(\"simple_prompt_inputs.jsonl\", \"rb\"),\n",
    "  purpose=\"batch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1cff61c4-da56-4fda-bf86-9777ae44f176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(id='batch_qAIvekErAMqji8fI4hSnOlri', completion_window='24h', created_at=1716293009, endpoint='/v1/chat/completions', input_file_id='file-SRYuSn4Dy9omkRYJSYy4uIo3', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1716379409, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'Evaluation of GPT-4o with using simple prompt'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_input_file_id = batch_input_file.id\n",
    "\n",
    "client.batches.create(\n",
    "    input_file_id=batch_input_file_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "      \"description\": \"Evaluation of GPT-3.5-Turbo with using simple prompt\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3d42d5ea-4fc1-4213-ae1d-51d545c8f1aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(id='batch_qAIvekErAMqji8fI4hSnOlri', completion_window='24h', created_at=1716293009, endpoint='/v1/chat/completions', input_file_id='file-SRYuSn4Dy9omkRYJSYy4uIo3', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1716298372, error_file_id=None, errors=None, expired_at=None, expires_at=1716379409, failed_at=None, finalizing_at=1716297920, in_progress_at=1716293011, metadata={'description': 'Evaluation of GPT-4o with using simple prompt'}, output_file_id='file-UYWoKFVlkUeVXqDgmAZNPENp', request_counts=BatchRequestCounts(completed=6811, failed=0, total=6811))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.batches.retrieve('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a1f8aeac-a1dc-4137-aaf0-684723f4676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = client.files.content('')\n",
    "simple_outputs = []\n",
    "for message in content.iter_lines():\n",
    "    simple_outputs.append(message)\n",
    "\n",
    "\n",
    "def save_list_as_jsonl(file_path, data):\n",
    "    with open(file_path, 'w') as f:\n",
    "        for item in data:\n",
    "            json.dump(item, f)\n",
    "            f.write('\\n')\n",
    "            \n",
    "save_list_as_jsonl('./Data/PredictionResult/gpt-3.5-turbo_simple-prompt_output.jsonl', simple_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d508d31-9b3c-4d28-9f21-a0486676254e",
   "metadata": {},
   "source": [
    "### role prompt version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4a54d8c5-83b2-4b12-a96c-c27be8dbc4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "api_key = ''\n",
    "client = OpenAI(api_key = api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2f5302d8-ced8-433d-b9b5-62ff88be947e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_input_file = client.files.create(\n",
    "  file=open(\"role_prompt_inputs.jsonl\", \"rb\"),\n",
    "  purpose=\"batch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b9a0a825-1e46-4fb7-a5a2-8181efdeb759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(id='batch_WR3K77Wx769tVsEbl8yXbgRO', completion_window='24h', created_at=1716304788, endpoint='/v1/chat/completions', input_file_id='file-ieK0RcKpfshB1YseGrcDqU8I', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1716391188, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'Evaluation of GPT-4o with using role prompt'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_input_file_id = batch_input_file.id\n",
    "\n",
    "client.batches.create(\n",
    "    input_file_id=batch_input_file_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "      \"description\": \"Evaluation of GPT-3.5-Turbo with using role prompt\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3d4adc0f-af77-46dd-9380-9d4992e94a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(id='batch_WR3K77Wx769tVsEbl8yXbgRO', completion_window='24h', created_at=1716304788, endpoint='/v1/chat/completions', input_file_id='file-ieK0RcKpfshB1YseGrcDqU8I', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1716319320, error_file_id=None, errors=None, expired_at=None, expires_at=1716391188, failed_at=None, finalizing_at=1716318808, in_progress_at=1716304790, metadata={'description': 'Evaluation of GPT-4o with using role prompt'}, output_file_id='file-hvd8cFGOLEu9dC4AiYPojfRF', request_counts=BatchRequestCounts(completed=6811, failed=0, total=6811))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.batches.retrieve('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4bb8902b-097e-4eb8-ab11-3cde91b4d413",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = client.files.content('')\n",
    "role_outputs = []\n",
    "for message in content.iter_lines():\n",
    "    role_outputs.append(message)\n",
    "\n",
    "\n",
    "def save_list_as_jsonl(file_path, data):\n",
    "    with open(file_path, 'w') as f:\n",
    "        for item in data:\n",
    "            json.dump(item, f)\n",
    "            f.write('\\n')\n",
    "            \n",
    "save_list_as_jsonl('./Data/PredictionResult/gpt-3.5-turbo_role-prompt_output.jsonl', role_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a2cd87-f8bf-4438-b954-e91c70a9e1b4",
   "metadata": {},
   "source": [
    "### instruction prompt version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4c5f306-864d-4a4a-9c2c-d9fd994437bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "api_key = ''\n",
    "client = OpenAI(api_key = api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c3018c2-a062-47ef-a4eb-7612b2fb753d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_input_file = client.files.create(\n",
    "  file=open(\"gpt-3.5-turbo_instruction_prompt_inputs.jsonl\", \"rb\"),\n",
    "  purpose=\"batch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb88b8c4-4df6-48d0-b34f-7af736ae90e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(id='batch_nyBi78MYjTIn3UvJjxwN9bz0', completion_window='24h', created_at=1716556131, endpoint='/v1/chat/completions', input_file_id='file-Xuu8fBFUJA09kN9WkiqNJLN8', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1716642531, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'Evaluation of GPT-3.5-turbo-0613 with using instruction prompt'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_input_file_id = batch_input_file.id\n",
    "\n",
    "client.batches.create(\n",
    "    input_file_id=batch_input_file_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "      \"description\": \"Evaluation of GPT-3.5-Turbo with using instruction prompt\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ccdde0f8-71f8-4824-b44a-37c3904419be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(id='batch_nyBi78MYjTIn3UvJjxwN9bz0', completion_window='24h', created_at=1716556131, endpoint='/v1/chat/completions', input_file_id='file-Xuu8fBFUJA09kN9WkiqNJLN8', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1716560134, error_file_id=None, errors=None, expired_at=None, expires_at=1716642531, failed_at=None, finalizing_at=1716559660, in_progress_at=1716556133, metadata={'description': 'Evaluation of GPT-3.5-turbo-0613 with using instruction prompt'}, output_file_id='file-9f8MFWPobdVdWjCRhBryuiBU', request_counts=BatchRequestCounts(completed=6811, failed=0, total=6811))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.batches.retrieve('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "afde6236-68de-4c19-bc65-0d6deaba4e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = client.files.content('')\n",
    "instruction_outputs = []\n",
    "for message in content.iter_lines():\n",
    "    instruction_outputs.append(message)\n",
    "\n",
    "def save_list_as_jsonl(file_path, data):\n",
    "    with open(file_path, 'w') as f:\n",
    "        for item in data:\n",
    "            json.dump(item, f)\n",
    "            f.write('\\n')\n",
    "            \n",
    "save_list_as_jsonl('./Data/PredictionResult/gpt-3.5-turbo_instruction-prompt_output.jsonl', instruction_outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
